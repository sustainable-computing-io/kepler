# Design Principles

The Kepler architecture is built on a set of core principles that drive all design decisions. Understanding these principles is essential for contributing to the project and maintaining architectural consistency.

## 1. Fair Power Allocation

> *"You can't rely on Prometheus scrapes for fairness. Processes that consumed power but aren't running anymore should be reported."*

### Problem Statement

Traditional monitoring systems only report currently running workloads, leading to unfair power attribution when processes terminate between scrapes. This creates several issues:

- **Attribution Gaps**: Power consumed by terminated processes is unaccounted for
- **Unfair Billing**: Running workloads get charged for terminated process energy
- **Incomplete Metrics**: Power consumption data has gaps and inconsistencies

### Solution: Terminated Workload Tracking

Kepler implements a comprehensive terminated workload tracking system:

```go
// Terminated workload trackers in PowerMonitor
terminatedProcessesTracker  *TerminatedResourceTracker[*Process]
terminatedContainersTracker *TerminatedResourceTracker[*Container]
terminatedVMsTracker        *TerminatedResourceTracker[*VirtualMachine]
terminatedPodsTracker       *TerminatedResourceTracker[*Pod]
```

**Key Features:**

- **Priority-Based Retention**: Keep highest energy consumers to ensure fair attribution
- **Export-Triggered Cleanup**: Clear terminated workloads only after they've been exported to prevent data loss
- **Configurable Capacity**: Control memory usage while maintaining fairness

**Configuration:**

```yaml
monitor:
  maxTerminated: 100  # Track top 100 terminated workloads by energy
  minTerminatedEnergyThreshold: 10  # Only track workloads with >10J consumption
```

## 2. Data Consistency, Completeness & Mathematical Integrity

> *"Data exported should be consistent, complete and not half complete"*

### Mathematical Relationships Enforced

Kepler enforces strict mathematical consistency across all power attribution levels:

```text
Node Watts = Node Active Watts + Node Idle Watts
Node Active Watts = Î£(Process Watts)
Container Watts = Î£(Process Watts in Container)
VM Watts = Î£(Process Watts associated with VM)
Pod Watts = Î£(Container Watts in Pod)
```

### Implementation Guarantees

- **Atomic Snapshots**: All related data captured at the same instant
- **Energy Conservation Validation**: Attribution totals must equal measured energy
- **Hierarchical Aggregation**: Bottom-up rollup ensures mathematical consistency
- **Immutable Data Structures**: Prevent partial updates during export

### Testing Strategy

```go
// Energy conservation tests validate:
assert.Equal(t, nodeActiveEnergy, sumOfProcessEnergies)
assert.Equal(t, containerEnergy, sumOfContainerProcessEnergies)
assert.Equal(t, podEnergy, sumOfPodContainerEnergies)
```

## 3. Computation-Presentation Separation (M/V Pattern)

> *"Keep Computation away from Presentation â†’ Allow multiple ways to present the same data"*

### Architecture Pattern

```text
Monitor (Model) â†’ PowerDataProvider Interface â†’ Multiple Exporters (Views)
```

### Current Exporters

- âœ… **Prometheus**: Production metrics endpoint with full Prometheus ecosystem integration
- âœ… **Stdout**: Development and debugging with human-readable output
- ðŸ”„ **OpenTelemetry**: Future extensibility for emerging observability standards

### Benefits

- **Extensibility**: Add new export formats without changing core logic
- **Flexibility**: Different presentation needs (dashboards, alerts, debugging)
- **Future-Proofing**: Ready for emerging standards and requirements
- **Testing**: Easy to validate computation logic independently from presentation

### M/V Pattern Implementation

```go
type PowerDataProvider interface {
    Snapshot() (*Snapshot, error)      // Core data access
    DataChannel() <-chan struct{}      // Change notifications
    ZoneNames() []string               // Metadata access
}
```

## 4. Data Freshness Guarantee

> *"Data presented should be as fresh as possible within the stale duration"*

### Freshness Controls

- **Configurable Staleness Threshold**: Default 10s, prevents serving outdated data
- **Automatic Refresh**: Fresh data computed on-demand when stale
- **Singleflight Protection**: Prevents redundant calculations during concurrent requests
- **Data Channel Notifications**: Signal exporters when new data is available

### Freshness Implementation

```go
func (pm *PowerMonitor) isFresh() bool {
    age := pm.clock.Now().Sub(snapshot.Timestamp)
    return age <= pm.maxStaleness
}

func (pm *PowerMonitor) Snapshot() (*Snapshot, error) {
    if !pm.isFresh() {
        pm.synchronizedPowerRefresh() // Automatic refresh
    }
    return pm.snapshot.Load(), nil
}
```

### Configuration

```yaml
monitor:
  staleness: 10s  # Data older than 10s triggers automatic refresh
```

## 5. Deterministic Processing

> *"Parallel vs Serial processing should not produce different results"*

### Thread Safety Guarantees

- **Atomic Snapshot Updates**: Single writer ensures consistency
- **Immutable Snapshots**: No partial modifications possible
- **Deterministic Attribution**: Same CPU time ratios â†’ same power attribution
- **Race-Free Calculations**: All concurrent access is read-only

### Implementation Patterns

```go
// Single writer pattern
func (pm *PowerMonitor) refreshSnapshot() error {
    // Only one goroutine can update snapshots
    newSnapshot := NewSnapshot()
    // ... perform calculations ...
    pm.snapshot.Store(newSnapshot) // Atomic update
}

// Multiple readers pattern
func (pm *PowerMonitor) Snapshot() (*Snapshot, error) {
    return pm.snapshot.Load(), nil // Lock-free read
}
```

### Testing Requirements

All concurrent code must be validated with race detection:

```bash
go test -race ./...
```

## 6. Prefer Package Reuse Over Reinvention

> *"Prefer reuse (of packages) over reinventing them (like in old kepler)"*

### Well-Maintained Dependencies

| Area               | Package                          | Benefit                           |
|--------------------|----------------------------------|-----------------------------------|
| Service Management | `oklog/run`                      | Coordinated lifecycle management  |
| Metrics            | `prometheus/client_golang`       | Standard Prometheus exposition    |
| Concurrency        | `golang.org/x/sync/singleflight` | Proven deduplication patterns     |
| Kubernetes         | `k8s.io/client-go`               | Native Kubernetes API integration |
| Configuration      | `alecthomas/kingpin/v2`          | Battle-tested CLI parsing         |
| Logging            | `log/slog`                       | Standard structured logging       |

### Package Reuse Benefits

- **Reduced Maintenance Burden**: Focus on core logic, not infrastructure
- **Battle-Tested Implementations**: Proven reliability and performance
- **Community Support**: Active maintenance and security updates
- **Standards Compliance**: Follow established patterns and conventions

### Evaluation Criteria

When choosing external packages:

1. **Active Maintenance**: Regular updates and responsive maintainers
2. **Production Usage**: Proven track record in production systems
3. **API Stability**: Stable interfaces that won't break frequently
4. **Performance**: Suitable for Kepler's performance requirements
5. **License Compatibility**: Compatible with Apache 2.0 license

## 7. Configurable Collection & Exposure

> *"Allow Users to configure what to collect and expose only those"*

### Metrics Level Configuration

Users can configure exactly what metrics to collect and expose:

```yaml
exporter:
  prometheus:
    metricsLevel: "container"  # node|process|container|vm|pod|all
```

### Current Support Matrix

| Level         | Status | Metrics                                   | Benefits                       |
|---------------|--------|-------------------------------------------|--------------------------------|
| **Node**      | âœ…      | `kepler_node_cpu_watts{zone="package"}`   | System-level monitoring        |
| **Process**   | ðŸ”„     | `kepler_process_cpu_watts{pid="1234"}`    | Fine-grained analysis          |
| **Container** | ðŸ”„     | `kepler_container_cpu_watts{id="abc123"}` | Container-level billing        |
| **VM**        | ðŸ”„     | `kepler_vm_cpu_watts{id="vm-123"}`        | Virtualization monitoring      |
| **Pod**       | âœ…      | `kepler_pod_cpu_watts{pod="webapp"}`      | Kubernetes workload monitoring |

### Configuration Benefits

- **Reduced Cardinality**: Lower storage and query costs for large clusters
- **Lower Resource Usage**: Collect only necessary data
- **Focused Monitoring**: Target specific workload types
- **Scalability**: Scale metrics collection based on cluster size

### Zone Filtering

```yaml
rapl:
  zones: ["package", "dram"]  # Only collect package and DRAM zones
```

## 8. Implementation Abstraction

> *"Allow implementation details to change without affecting the rest of the code. E.g: eBPF is only a means to an end"*

### Interface-Based Design

Core abstractions enable implementation flexibility:

```go
// Hardware abstraction - can be RAPL, eBPF, or other implementations
type CPUPowerMeter interface {
    Zones() ([]EnergyZone, error)
    PrimaryEnergyZone() (EnergyZone, error)
}

// Resource tracking abstraction - can be procfs, eBPF, or other methods
type Informer interface {
    Refresh() error
    Processes() *Processes
    Containers() *Containers
}
```

### Current and Future Implementations

| Layer                 | Current            | Future             | Abstraction Benefit           |
|-----------------------|--------------------|--------------------|-------------------------------|
| **Hardware**          | RAPL sysfs         | eBPF perf counters | Pluggable energy sources      |
| **Resource Tracking** | procfs reader      | eBPF tracer        | Different collection methods  |
| **Export**            | Prometheus, stdout | OpenTelemetry      | Multiple presentation formats |

### Design Benefits

- **Technology Evolution**: Adopt new technologies without architectural changes
- **Platform Support**: Support different platforms through different implementations
- **Testing**: Easy to create fake implementations for testing
- **Performance Optimization**: Swap implementations based on performance needs

## 9. Simple Configuration & Low Learning Curve

> *"Simple Configuration to reduce learning curve - keep flags and configuration in sync (as much as possible)"*

### Hierarchical Configuration

Configuration follows a clear precedence order:

1. **CLI Flags** (highest) - for operational overrides
2. **YAML Files** (middle) - for persistent configuration
3. **Defaults** (lowest) - for sensible out-of-box experience

### Synchronization Strategy

- **Operational Flags**: Every YAML config option has corresponding CLI flag where operationally relevant
- **Development Options**: `dev.*` settings intentionally not exposed as CLI flags (internal only)
- **Consistent Naming**: `--exporter.prometheus.enabled` â†” `exporter.prometheus.enabled`

### Examples

```bash
# CLI override of YAML config
kepler --config=production.yaml --log.level=debug --monitor.interval=5s

# Development mode (not exposed as CLI flag - internal only)
# Must be set in YAML: dev.fake_cpu_meter.enabled: true
```

### Design Philosophy

- **Operational vs Development**: Clear separation between production and development settings
- **Discoverability**: All options documented with clear descriptions
- **Validation**: Configuration validation with helpful error messages
- **Defaults**: Sensible defaults that work out-of-the-box

## How Principles Shape Architecture

These principles directly influenced major architectural decisions:

| Principle                  | Architectural Impact                              | Implementation                                   |
|----------------------------|---------------------------------------------------|--------------------------------------------------|
| Fair Allocation            | Terminated workload tracking system               | `TerminatedResourceTracker` with priority queues |
| Mathematical Integrity     | Atomic snapshots + energy conservation            | Immutable `Snapshot` with validation             |
| M/V Separation             | PowerDataProvider interface + pluggable exporters | Interface-based exporter system                  |
| Data Freshness             | Staleness control + singleflight pattern          | `isFresh()` checks + automatic refresh           |
| Deterministic Processing   | Thread-safe design + immutable snapshots          | Single writer, multiple readers                  |
| Package Reuse              | Minimal custom implementations + proven libraries | Strategic dependency selection                   |
| Configurable Exposure      | Metrics level system + zone filtering             | `config.Level` + filtering logic                 |
| Implementation Abstraction | Interface-based layers + dependency injection     | Clean interface boundaries                       |
| Simple Configuration       | Hierarchical config + CLI/YAML sync               | `kingpin` + YAML parsing                         |

---

## Next Steps

After understanding these principles, explore:

- **[System Components](components.md)**: How principles are implemented in practice
- **[Data Flow](data-flow.md)**: How principles ensure fair and accurate power attribution
- **[Concurrency](concurrency.md)**: How deterministic processing is achieved
